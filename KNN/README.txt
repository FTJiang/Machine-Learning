Algorithm: K Nearest Neighbors
Environment: Matlab 2015b

This is a facial attractiveness classification task: given a picture of a face, you need to predict whether the average rating of the face is hot or not. So, each row corresponds to a data point (a picture). Each column is a feature, a pixel. The value of the feature is the value of the pixel in a grayscale image. cosineDistance.m implements the cosine distance, a simple distance function. It takes two feature vectors x and y, and computes a nengative, symmetric distance between x and y.

cosineDistance.m
This file is used for compute distance between data. In the formula, I use 1-cosineDistance, therefore, the nearest neighbors are the smallest value of distance.

error_compute.m
I used knnclassify function provided by matlab to generate training and test error to compare with my program. To use this program, you need to provide KNN.mat which contains testdata, testdata and trainlabels.

KNNtrain.m
Program used to compute training error, input is training data and training labels.
example usage: KNNtrain(1,traindata,trainlabels);

KNNTrainSimplify.m
In order to avoid recomputing distance matrix, I write this program which take distance matrix as input. To generate distance matrix, you should uncomment 24 and 26 line in KNNtrain.m and run it ones. The distance matrix generated by KNNtrain.m will be took as input of KNNtrainSimplity.m
example usage: KNNTrainSimplify(trainindex,train_label_matrix,trainlabels);

KNNtest.m and KNNTestSimplify.m
Similar to KNNtrain.m and KNNTrainSimplify.m. They also take in testlabels as input except the input of training program.
example usage: KNNTestSimplify(index,label_matrix,testlabels);
